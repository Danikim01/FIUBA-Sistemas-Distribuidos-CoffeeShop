"""Comprehensive tests for AggregatorStateStore to verify state persistence correctness."""

import json
import os
import shutil
import tempfile
import threading
import time
from pathlib import Path
from unittest.mock import patch

import pytest

# Add src to path for imports
import sys

PROJECT_ROOT = Path(__file__).resolve().parent.parent
SRC_PATH = PROJECT_ROOT / "src"
WORKERS_PATH = SRC_PATH / "workers"
UTILS_PATH = WORKERS_PATH / "utils"

if str(SRC_PATH) not in sys.path:
    sys.path.insert(0, str(SRC_PATH))
if str(WORKERS_PATH) not in sys.path:
    sys.path.insert(0, str(WORKERS_PATH))
if str(UTILS_PATH) not in sys.path:
    sys.path.insert(0, str(UTILS_PATH))

from workers.utils.aggregator_state_store import AggregatorStateStore


class TestAggregatorStateStore:
    """Test suite for AggregatorStateStore covering edge cases."""
    
    @pytest.fixture
    def temp_dir(self):
        """Create a temporary directory for test state files."""
        temp_path = tempfile.mkdtemp()
        yield temp_path
        shutil.rmtree(temp_path, ignore_errors=True)
    
    @pytest.fixture
    def store(self, temp_dir):
        """Create an AggregatorStateStore instance with temp directory."""
        with patch.dict(os.environ, {'STATE_DIR': temp_dir}):
            store = AggregatorStateStore("test-aggregator")
            yield store
    
    def test_basic_persistence(self, store):
        """Test basic save and get functionality."""
        client_id = "test-client-1"
        state_data = {
            "quantity_totals": {"2024-01": {"item-1": 100, "item-2": 200}},
            "profit_totals": {"2024-01": {"item-1": 50.5, "item-2": 100.75}}
        }
        
        # Initially no state
        initial_state = store.get_state(client_id)
        assert initial_state == {}
        
        # Save state
        store.save_state(client_id, state_data)
        
        # Get state
        retrieved_state = store.get_state(client_id)
        assert retrieved_state == state_data
        assert retrieved_state["quantity_totals"]["2024-01"]["item-1"] == 100
        assert retrieved_state["profit_totals"]["2024-01"]["item-2"] == 100.75
    
    def test_restoration_after_restart(self, store, temp_dir):
        """Test that state is restored correctly after worker restart."""
        client_id = "test-client-2"
        state_data = {
            "quantity_totals": {"2024-01": {"item-1": 100}},
            "profit_totals": {"2024-01": {"item-1": 50.5}}
        }
        
        # Save state
        store.save_state(client_id, state_data)
        
        # Create new store instance (simulating restart)
        with patch.dict(os.environ, {'STATE_DIR': temp_dir}):
            new_store = AggregatorStateStore("test-aggregator")
            
            # State should be restored
            retrieved_state = new_store.get_state(client_id)
            assert retrieved_state == state_data
            assert retrieved_state["quantity_totals"]["2024-01"]["item-1"] == 100
    
    def test_multiple_clients(self, store):
        """Test that different clients have separate state."""
        client1 = "client-1"
        client2 = "client-2"
        
        state1 = {"data": {"key1": "value1"}}
        state2 = {"data": {"key2": "value2"}}
        
        store.save_state(client1, state1)
        store.save_state(client2, state2)
        
        assert store.get_state(client1) == state1
        assert store.get_state(client2) == state2
        assert store.get_state(client1) != state2
        assert store.get_state(client2) != state1
    
    def test_state_update(self, store):
        """Test updating state for the same client."""
        client_id = "test-client-update"
        
        # Initial state
        initial_state = {"quantity_totals": {"2024-01": {"item-1": 100}}}
        store.save_state(client_id, initial_state)
        
        # Update state
        updated_state = {
            "quantity_totals": {"2024-01": {"item-1": 200, "item-2": 150}},
            "profit_totals": {"2024-01": {"item-1": 100.0}}
        }
        store.save_state(client_id, updated_state)
        
        # Verify update
        retrieved = store.get_state(client_id)
        assert retrieved == updated_state
        assert retrieved["quantity_totals"]["2024-01"]["item-1"] == 200
        assert "item-2" in retrieved["quantity_totals"]["2024-01"]
    
    def test_checksum_validation(self, store, temp_dir):
        """Test that checksum validation works correctly."""
        client_id = "test-client-checksum"
        state_data = {"data": {"key": "value"}}
        
        # Save state
        store.save_state(client_id, state_data)
        
        # Verify checksum in file
        store_path = Path(temp_dir) / "aggregator_state" / "test-aggregator"
        safe_id = client_id.replace('/', '_').replace('\\', '_').replace(':', '_')
        client_file = store_path / f"{safe_id}.json"
        
        assert client_file.exists()
        
        with client_file.open('r', encoding='utf-8') as f:
            data = json.load(f)
        
        assert 'checksum' in data
        assert 'client_id' in data
        assert 'state' in data
        assert data['state'] == state_data
        
        # Verify checksum is valid
        payload = {
            'client_id': data['client_id'],
            'state': data['state']
        }
        expected_checksum = store._compute_checksum(payload)
        assert data['checksum'] == expected_checksum
    
    def test_corrupted_file_recovery(self, store, temp_dir):
        """Test recovery from corrupted file using backup (checksum mismatch)."""
        client_id = "test-client-corrupted"
        
        # Save initial state
        initial_state = {"data": {"key": "initial"}}
        store.save_state(client_id, initial_state)
        
        # Save again to create backup
        updated_state = {"data": {"key": "updated"}}
        store.save_state(client_id, updated_state)
        
        # Verify backup exists
        store_path = Path(temp_dir) / "aggregator_state" / "test-aggregator"
        safe_id = client_id.replace('/', '_').replace('\\', '_').replace(':', '_')
        client_file = store_path / f"{safe_id}.json"
        backup_file = store_path / f"{safe_id}.backup.json"
        
        assert backup_file.exists(), "Backup file should exist after second save"
        
        # Corrupt the checksum in main file (but keep JSON valid)
        # This will trigger checksum validation and recovery from backup
        with client_file.open('r', encoding='utf-8') as f:
            data = json.load(f)
        data['checksum'] = 'invalid_checksum_12345'
        with client_file.open('w', encoding='utf-8') as f:
            json.dump(data, f)
        
        # Create new store - should recover from backup
        with patch.dict(os.environ, {'STATE_DIR': temp_dir}):
            new_store = AggregatorStateStore("test-aggregator")
            
            # Should have recovered from backup
            # Backup contains the PREVIOUS state (initial_state) before the last write
            retrieved = new_store.get_state(client_id)
            # The backup should contain initial_state (the state before updated_state was saved)
            # Recovery should restore the backup state (initial_state)
            assert retrieved == initial_state, \
                f"Should recover initial_state from backup, got: {retrieved}"
            # The important thing is that we recovered SOME valid state, not empty
            assert retrieved != {}, "Should have recovered valid state from backup"
            assert client_file.exists(), "Main file should be restored from backup"
    
    def test_corrupted_json_file(self, store, temp_dir):
        """Test handling of corrupted JSON files."""
        client_id = "test-client-corrupted-json"
        
        # Create a corrupted JSON file
        store_path = Path(temp_dir) / "aggregator_state" / "test-aggregator"
        store_path.mkdir(parents=True, exist_ok=True)
        safe_id = client_id.replace('/', '_').replace('\\', '_').replace(':', '_')
        corrupted_file = store_path / f"{safe_id}.json"
        corrupted_file.write_text("not valid json { invalid }", encoding="utf-8")
        
        # Store should handle corruption gracefully
        with patch.dict(os.environ, {'STATE_DIR': temp_dir}):
            new_store = AggregatorStateStore("test-aggregator")
            # Should not crash, should return empty state
            state = new_store.get_state(client_id)
            assert state == {}
            # Should be able to save new state
            new_state = {"data": {"key": "new"}}
            new_store.save_state(client_id, new_state)
            assert new_store.get_state(client_id) == new_state
    
    def test_invalid_json_structure(self, store, temp_dir):
        """Test handling of JSON files with invalid structure."""
        client_id = "test-client-invalid-structure"
        
        # Create JSON file with invalid structure (not a dict)
        store_path = Path(temp_dir) / "aggregator_state" / "test-aggregator"
        store_path.mkdir(parents=True, exist_ok=True)
        safe_id = client_id.replace('/', '_').replace('\\', '_').replace(':', '_')
        invalid_file = store_path / f"{safe_id}.json"
        invalid_file.write_text('["not", "a", "dict"]', encoding="utf-8")
        
        with patch.dict(os.environ, {'STATE_DIR': temp_dir}):
            new_store = AggregatorStateStore("test-aggregator")
            # Should handle invalid structure gracefully
            state = new_store.get_state(client_id)
            assert state == {}
            # Should be able to save new state
            new_state = {"data": {"key": "new"}}
            new_store.save_state(client_id, new_state)
            assert new_store.get_state(client_id) == new_state
    
    def test_empty_state(self, store):
        """Test handling of empty state."""
        client_id = "test-client-empty"
        empty_state = {}
        
        store.save_state(client_id, empty_state)
        retrieved = store.get_state(client_id)
        assert retrieved == {}
        # has_state returns bool(cache[client_id]) which is False for empty dict
        # but the file exists on disk, so we check the file directly
        # Note: has_state checks cache first, and empty dict is falsy, so it returns False
        # This is expected behavior - an empty state is considered as "no state"
        # If we want to distinguish between "no file" and "empty state", we'd need to change has_state
        # For now, we just verify the state can be saved and retrieved
        assert retrieved == empty_state
    
    def test_clear_client(self, store):
        """Test clearing client state."""
        client_id = "test-client-clear"
        state_data = {"data": {"key": "value"}}
        
        # Save state
        store.save_state(client_id, state_data)
        assert store.has_state(client_id)
        assert store.get_state(client_id) == state_data
        
        # Clear client
        store.clear_client(client_id)
        
        # Should not have state anymore
        assert not store.has_state(client_id)
        assert store.get_state(client_id) == {}
    
    def test_clear_nonexistent_client(self, store):
        """Test clearing a client that doesn't exist."""
        client_id = "test-client-nonexistent"
        
        # Should not crash
        store.clear_client(client_id)
        assert not store.has_state(client_id)
        assert store.get_state(client_id) == {}
    
    def test_has_state(self, store):
        """Test has_state method."""
        client_id = "test-client-has-state"
        
        # Initially no state
        assert not store.has_state(client_id)
        
        # Save state
        state_data = {"data": {"key": "value"}}
        store.save_state(client_id, state_data)
        assert store.has_state(client_id)
        
        # Clear state
        store.clear_client(client_id)
        assert not store.has_state(client_id)
    
    def test_special_characters_in_client_id(self, store):
        """Test that special characters in client_id are handled correctly."""
        client_id = "client/with\\special:chars"
        state_data = {"data": {"key": "value"}}
        
        store.save_state(client_id, state_data)
        assert store.get_state(client_id) == state_data
        
        # Should persist and restore correctly
        store2 = AggregatorStateStore("test-aggregator")
        assert store2.get_state(client_id) == state_data
    
    def test_concurrent_access(self, store):
        """Test thread-safety with concurrent access."""
        client_id = "test-client-concurrent"
        num_threads = 10
        updates_per_thread = 50
        
        def update_state(thread_id):
            for i in range(updates_per_thread):
                state = {
                    "thread": thread_id,
                    "update": i,
                    "data": {f"key-{thread_id}-{i}": f"value-{thread_id}-{i}"}
                }
                store.save_state(client_id, state)
        
        threads = []
        for i in range(num_threads):
            t = threading.Thread(target=update_state, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # Verify final state exists (last write wins)
        final_state = store.get_state(client_id)
        assert final_state is not None
        assert "thread" in final_state
        assert "update" in final_state
    
    def test_concurrent_read_write(self, store):
        """Test concurrent read and write operations."""
        client_id = "test-client-read-write"
        num_writers = 5
        num_readers = 5
        updates_per_writer = 20
        
        def writer(thread_id):
            for i in range(updates_per_writer):
                state = {"writer": thread_id, "update": i}
                store.save_state(client_id, state)
                time.sleep(0.001)
        
        def reader(thread_id):
            for i in range(updates_per_writer):
                # Just read, might not be the latest
                store.get_state(client_id)
                time.sleep(0.001)
        
        threads = []
        for i in range(num_writers):
            t = threading.Thread(target=writer, args=(i,))
            threads.append(t)
            t.start()
        
        for i in range(num_readers):
            t = threading.Thread(target=reader, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # Verify final state exists
        final_state = store.get_state(client_id)
        assert final_state is not None
        assert "writer" in final_state
    
    def test_temp_file_cleanup(self, store, temp_dir):
        """Test temp file cleanup on startup."""
        # Create a temp file manually (simulating crash)
        store_path = Path(temp_dir) / "aggregator_state" / "test-aggregator"
        store_path.mkdir(parents=True, exist_ok=True)
        temp_file = store_path / "test-client.temp.json"
        temp_file.write_text('{"incomplete": "write"}', encoding="utf-8")
        
        assert temp_file.exists(), "Temp file should exist before cleanup"
        
        # Create store - should clean up temp file
        with patch.dict(os.environ, {'STATE_DIR': temp_dir}):
            new_store = AggregatorStateStore("test-aggregator")
        
        # Temp file should be gone
        assert not temp_file.exists(), "Temp file should be cleaned up on startup"
    
    def test_atomic_write(self, store, temp_dir):
        """Test that writes are atomic (temp file pattern)."""
        client_id = "test-client-atomic"
        state_data = {"data": {"key": "value"}}
        
        # Save state
        store.save_state(client_id, state_data)
        
        # Verify file exists and temp file doesn't
        store_path = Path(temp_dir) / "aggregator_state" / "test-aggregator"
        safe_id = client_id.replace('/', '_').replace('\\', '_').replace(':', '_')
        path = store_path / f"{safe_id}.json"
        temp_path = store_path / f"{safe_id}.temp.json"
        
        assert path.exists()
        assert not temp_path.exists(), "Temp file should be cleaned up after write"
    
    def test_complex_nested_state(self, store):
        """Test with complex nested state structures."""
        client_id = "test-client-complex"
        complex_state = {
            "quantity_totals": {
                "2024-01": {
                    "item-1": 100,
                    "item-2": 200,
                    "item-3": 300
                },
                "2024-02": {
                    "item-1": 150,
                    "item-2": 250
                }
            },
            "profit_totals": {
                "2024-01": {
                    "item-1": 50.5,
                    "item-2": 100.75,
                    "item-3": 150.25
                }
            },
            "metadata": {
                "last_updated": "2024-01-01T00:00:00Z",
                "version": 1
            }
        }
        
        store.save_state(client_id, complex_state)
        retrieved = store.get_state(client_id)
        
        assert retrieved == complex_state
        assert retrieved["quantity_totals"]["2024-01"]["item-1"] == 100
        assert retrieved["profit_totals"]["2024-01"]["item-2"] == 100.75
        assert retrieved["metadata"]["version"] == 1
    
    def test_large_state(self, store):
        """Test with large state data."""
        client_id = "test-client-large"
        large_state = {
            "data": {f"key-{i}": f"value-{i}" for i in range(1000)}
        }
        
        store.save_state(client_id, large_state)
        retrieved = store.get_state(client_id)
        
        assert retrieved == large_state
        assert len(retrieved["data"]) == 1000
    
    def test_unicode_in_state(self, store):
        """Test handling of Unicode characters in state."""
        client_id = "test-client-unicode"
        unicode_state = {
            "data": {
                "emoji": "ðŸš€",
                "spanish": "EspaÃ±ol",
                "chinese": "ä¸­æ–‡",
                "arabic": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
            }
        }
        
        store.save_state(client_id, unicode_state)
        retrieved = store.get_state(client_id)
        
        assert retrieved == unicode_state
        assert retrieved["data"]["emoji"] == "ðŸš€"
        assert retrieved["data"]["chinese"] == "ä¸­æ–‡"
    
    def test_backup_creation(self, store, temp_dir):
        """Test that backup is created on subsequent saves."""
        client_id = "test-client-backup"
        
        # First save - no backup yet
        state1 = {"data": {"key": "value1"}}
        store.save_state(client_id, state1)
        
        store_path = Path(temp_dir) / "aggregator_state" / "test-aggregator"
        safe_id = client_id.replace('/', '_').replace('\\', '_').replace(':', '_')
        backup_file = store_path / f"{safe_id}.backup.json"
        
        # Second save - backup should be created
        state2 = {"data": {"key": "value2"}}
        store.save_state(client_id, state2)
        
        assert backup_file.exists(), "Backup file should exist after second save"
        
        # Verify backup contains previous state
        with backup_file.open('r', encoding='utf-8') as f:
            backup_data = json.load(f)
        assert backup_data['state'] == state1
    
    def test_checksum_mismatch_handling(self, store, temp_dir):
        """Test handling of checksum mismatch."""
        client_id = "test-client-checksum-mismatch"
        
        # Save initial state
        initial_state = {"data": {"key": "initial"}}
        store.save_state(client_id, initial_state)
        
        # Save again to create backup
        updated_state = {"data": {"key": "updated"}}
        store.save_state(client_id, updated_state)
        
        # Corrupt the checksum in main file
        store_path = Path(temp_dir) / "aggregator_state" / "test-aggregator"
        safe_id = client_id.replace('/', '_').replace('\\', '_').replace(':', '_')
        client_file = store_path / f"{safe_id}.json"
        
        with client_file.open('r', encoding='utf-8') as f:
            data = json.load(f)
        data['checksum'] = 'invalid_checksum'
        with client_file.open('w', encoding='utf-8') as f:
            json.dump(data, f)
        
        # Create new store - should recover from backup
        with patch.dict(os.environ, {'STATE_DIR': temp_dir}):
            new_store = AggregatorStateStore("test-aggregator")
            
            # Should have recovered from backup
            retrieved = new_store.get_state(client_id)
            # Should have some valid state (either initial or updated)
            assert retrieved in [initial_state, updated_state]
    
    def test_multiple_worker_labels(self, store, temp_dir):
        """Test that different worker labels have separate state directories."""
        client_id = "test-client"
        state_data = {"data": {"key": "value"}}
        
        # Save with first worker label
        store.save_state(client_id, state_data)
        
        # Create store with different worker label
        with patch.dict(os.environ, {'STATE_DIR': temp_dir}):
            store2 = AggregatorStateStore("test-aggregator-2")
            
            # Should have separate state
            assert store2.get_state(client_id) == {}
            
            # Save with second worker label
            state_data2 = {"data": {"key": "value2"}}
            store2.save_state(client_id, state_data2)
            
            # Original store should still have original state
            assert store.get_state(client_id) == state_data
            # New store should have new state
            assert store2.get_state(client_id) == state_data2
    
    def test_state_isolation(self, store):
        """Test that state changes don't affect cached copies."""
        client_id = "test-client-isolation"
        state_data = {"data": {"key": "value"}}
        
        store.save_state(client_id, state_data)
        
        # Get state (returns shallow copy)
        retrieved1 = store.get_state(client_id)
        retrieved2 = store.get_state(client_id)
        
        # Modify top-level key (should not affect store due to shallow copy)
        retrieved1["new_top_key"] = "new_value"
        
        # Get state again - should be unchanged
        retrieved3 = store.get_state(client_id)
        assert "new_top_key" not in retrieved3
        assert retrieved3 == state_data
        
        # Note: get_state() uses .copy() which is shallow copy
        # Modifying nested structures would affect the original
        # This is acceptable behavior for this implementation


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])

